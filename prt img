import numpy as np
import cv2 as cv

MIN_MATCH_COUNT = 10

# 讀取img3
img3 = cv.imread("C:\\Users\\small\\yolov5-master\\0313\\jpg\\14\\23\\23-1.jpg", 1) # trainImage

# 初始化 SIFT 檢測器
sift = cv.SIFT_create()

# 使用 SIFT 找到img3的關鍵點和描述子
kp3, des3 = sift.detectAndCompute(img3, None)

# 定義 FLANN 參數
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
search_params = dict(checks=50)

# 創建 FLANN 匹配器
flann = cv.FlannBasedMatcher(index_params, search_params)

# 儲存所有方框的座標
all_boxes = []

# 儲存所有中心點座標
center_points = []

# 儲存每個方框的平均特徵點
average_keypoints_in_boxes = []

# 儲存每個方框內距離平均特徵點最遠的特徵點
farthest_keypoints_in_boxes = []

# 儲存每個方框內最遠特徵點與平均特徵點之間的距離
distances = []

# 讀取10張圖片
for i in range(1, 11):
    # 讀取影像
    img = cv.imread(f'output_frames/frame_{i}.jpg', 1)  # queryImage

    # 使用 SIFT 找到關鍵點和描述子
    kp1, des1 = sift.detectAndCompute(img, None)

    # 進行特徵匹配
    matches = flann.knnMatch(des1, des3, k=2)

    # 根據 Lowe's ratio 測試存儲所有良好的匹配
    good = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good.append(m)

    # 執行 Homography 變換
    if len(good) > MIN_MATCH_COUNT:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp3[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)

        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)
        matchesMask = mask.ravel().tolist()

        h, w, d = img.shape
        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
        dst = cv.perspectiveTransform(pts, M)
        x1, y1 = np.int32(dst[0][0])
        x2, y2 = np.int32(dst[1][0])
        x3, y3 = np.int32(dst[2][0])
        x4, y4 = np.int32(dst[3][0])
        center_x = (x1 + x2 + x3 + x4) / 4
        center_y = (y1 + y2 + y3 + y4) / 4
        print("中心坐標為:", center_x, center_y)
        center_points.append((center_x, center_y))

        all_boxes.append(np.int32(dst))

        # 計算方框內關鍵點的平均值
        box_keypoints = []
        for kp in kp1:
            kp_pt = np.array(kp.pt)
            if cv.pointPolygonTest(np.array(dst), kp_pt, False) >= 0:
                box_keypoints.append(kp.pt)
        box_keypoints = np.array(box_keypoints)
        avg_keypoint = np.mean(box_keypoints, axis=0)
        farthest_keypoint = box_keypoints[np.argmax(np.linalg.norm(box_keypoints - avg_keypoint, axis=1))]
        farthest_keypoints_in_boxes.append(farthest_keypoint)
        # 計算最遠特徵點與平均特徵點之間的距離
        distance3 = np.linalg.norm(farthest_keypoint - avg_keypoint)
        distances.append(distance3)
        print(f"方框 {i} 的平均特徵點: {avg_keypoint}")
        print(f"方框 {i}內距離平均特徵點最遠的特徵點: {farthest_keypoint}")
        print(f"方框{i} 距離3:{distance3}")

    else:
        print(f"Not enough matches are found in frame {i} - {len(good)}/{MIN_MATCH_COUNT}")

    # 儲存影像 img 的所有特徵點座標
    img_keypoints = []
    for kp in kp1:
        img_keypoints.append(kp.pt)

    # 計算影像 img 的平均特徵點
    img_average_point = np.mean(img_keypoints, axis=0)

    print("影像 img 的平均特徵點:", img_average_point)

    # 初始化最大距離為負無窮大
    max_distance = float('-inf')
    farthest_point = None

    # 找出距離平均特徵點最遠的特徵點
    for kp in img_keypoints:
        distance = np.linalg.norm(np.array(kp) - img_average_point)
        if distance > max_distance:
            max_distance = distance
            farthest_point = kp

    print("img影像中距離平均特徵點最遠的特徵點:", farthest_point)
    print("距離:", max_distance)
    print("縮放比例:", distance3 / max_distance)

# 逐個處理每個方框
for idx, box in enumerate(all_boxes):
    # 提取方框的範圍
    x, y, w, h = cv.boundingRect(box)

    # 從原始圖像中提取方框內的圖像
    cropped_img = img[y:y+h, x:x+w]

    # 將提取的圖像保存為 JPG 文件
    cv.imwrite(f"C:\\Users\\small\\yolov5-master\\img\\prtimg\\cropped_image_{idx}.jpg", cropped_img)

# 將所有方框繪製到img3上
color = (0, 255, 0)  # BGR
color2 = (0, 0, 255) # BGR
for box in all_boxes:
    img3 = cv.polylines(img3, [box], True, color, 3, cv.LINE_AA)
# 將所有中心點標示出來
for point in center_points:
    center_x, center_y = map(int, point)
    cv.circle(img3, (center_x, center_y), radius=5, color=(255, 255, 255), thickness=25)
# 將所有中心點連接成直線
for i in range(len(center_points) - 1):
    cv.line(img3, tuple(map(int, center_points[i])), tuple(map(int, center_points[i + 1])), color2, 10)
# 顯示結果
cv.namedWindow("All Boxes", cv.WINDOW_NORMAL)
cv.imshow("All Boxes", img3)
cv.waitKey(0)
cv.destroyAllWindows()
